<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>cs231nä½œä¸š3ç¬”è®° - PzNotes - Learning and Sharing</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="pzhang" />
  <meta name="description" content="ç®€ä»‹ åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚
" />

  <meta name="keywords" content="Geophysics, Computer Vision, Machine Learning" />






<meta name="generator" content="Hugo 0.53" />


<link rel="canonical" href="https://whu-pzhang.github.io/cs231n-assignment3/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="cs231nä½œä¸š3ç¬”è®°" />
<meta property="og:description" content="ç®€ä»‹

åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://whu-pzhang.github.io/cs231n-assignment3/" /><meta property="article:published_time" content="2018-12-20T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-12-20T00:00:00&#43;00:00"/>

<meta itemprop="name" content="cs231nä½œä¸š3ç¬”è®°">
<meta itemprop="description" content="ç®€ä»‹

åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚">


<meta itemprop="datePublished" content="2018-12-20T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-12-20T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="4725">



<meta itemprop="keywords" content="Python,NumPy,PyTorch," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="cs231nä½œä¸š3ç¬”è®°"/>
<meta name="twitter:description" content="ç®€ä»‹

åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">PzNotes</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/notes/">
        <li class="mobile-menu-item">Notes</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">PzNotes</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/notes/">Notes</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">cs231nä½œä¸š3ç¬”è®°</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-12-20 </span>
        <div class="post-category">
            
              <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"> è®¡ç®—æœºè§†è§‰ </a>
            
          </div>
        <span class="more-meta"> çº¦ 4725 å­— </span>
        <span class="more-meta"> é¢„è®¡é˜…è¯» 10 åˆ†é’Ÿ </span>
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">æ–‡ç« ç›®å½•</h2>
  
  <div class="post-toc-content">
    
  </div>
</div>

    
    <div class="post-content">
      <h2 id="ç®€ä»‹">ç®€ä»‹</h2>

<p>åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚</p>

<h2 id="rnn-captioning">RNN captioning</h2>

<p>å¸¸è§„ DNN å’Œ CNN åªèƒ½ä¾æ¬¡å¤„ç†ä¸€ä¸ªä¸ªçš„è¾“å…¥ï¼Œè¾“å…¥ä¹‹é—´æ˜¯å®Œå…¨æ²¡æœ‰è”ç³»çš„ï¼Œè¿™å¯¹äºå›¾åƒåˆ†ç±»çš„ä»»åŠ¡æ¥è¯´
æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æŸäº›éœ€è¦å¤„ç†åºåˆ—ä¹‹é—´å…³ç³»çš„ä»»åŠ¡è€Œè¨€å°±ä¸é€‚åˆäº†ã€‚ä¾‹å¦‚ï¼š</p>

<ol>
<li>å›¾åƒæ ‡æ³¨é—®é¢˜(one to many)ï¼š image -&gt; sequence of words</li>
<li>æƒ…æ„Ÿåˆ†ç±»(many to one): sequence of words -&gt; sentiment</li>
<li>æœºå™¨ç¿»è¯‘(many to many): seq of words -&gt; seq of words</li>
<li>å¸§çº§åˆ«çš„è§†é¢‘åˆ†ç±»(many to many)</li>
<li>â€¦â€¦</li>
</ol>

<p>ä¸ºäº†æ›´å¥½åœ°å¤„ç†åºåˆ—çš„ä¿¡æ¯ï¼ŒRNN(Recurrent Neural Network)è¯ç”Ÿäº†ã€‚
RNN éœ€è¦é¢„æµ‹ä¸€ä¸ªå’Œæ—¶é—´ç›¸å…³çš„é‡ï¼Œå…¶åŸºæœ¬æ¶æ„å¦‚ä¸‹ï¼š</p>

<p><figure><img src="/images/rnn.jpg" alt=""></figure></p>

<p>æ¯ä¸ªæ—¶é—´æ­¥éƒ½è¦æ ¹æ®å‰ä¸€ä¸ªçŠ¶æ€å’Œå½“å‰è¾“å…¥è®¡ç®—ä¸€ä¸ªæ–°çš„çŠ¶æ€ã€‚</p>

<p><span  class="math">\[
\boldsymbol{h}_t = f_W (\boldsymbol{h}_{t-1}, \boldsymbol{x}_t) \\
\downarrow \\
\boldsymbol{h}_t = tanh (\mathbf{W}_{hh}\boldsymbol{h}_{t-1} + \mathbf{W}_{xh} \boldsymbol{x}_t)
\]</span></p>

<p>å‘ä¸Šçš„ç®­å¤´ä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼Œæ˜¯ä¸€ä¸ª softmax å±‚</p>

<p><span  class="math">\[
\boldsymbol{y}_t = Softmax (\mathbf{W}_{hy} * \boldsymbol{h}_t)
\]</span></p>

<p>æ ¹æ®ä¸Šè¿°å…¬å¼ï¼ŒRNN å•å…ƒçš„ <code>rnn_step_forward</code> å¦‚ä¸‹ï¼š</p>

<pre><code class="language-python">prev_hWh = prev_h @ Wh                          # (1)
xWx = x @ Wx                                    # (2)
hsum = prev_hWh + xWx + b                       # (3)
next_h = np.tanh(hsum)                          # (4)
</code></pre>

<p>æ ¹æ®è®¡ç®—å›¾åæ¨ï¼Œbackward ä¹Ÿå¾ˆç®€å•ï¼š</p>

<pre><code class="language-python">dhsum = (1 - np.tanh(hsum)**2) * dnext_h      # (4)
dprev_hWh = dhsum                             # (3)
dxWx = dhsum                                  # (3)
db = np.sum(dhsum, axis=0)                    # (3)
dx = dxWx @ Wx.T                              # (2)
dWx = x.T @ dxWx                              # (2)
dWh = prev_h.T @ dprev_hWh                    # (1)
dprev_h = dprev_hWh @ Wh.T                    # (1)
</code></pre>

<p>æ¥ä¸‹æ¥å°±æ˜¯å®Œæ•´çš„ RNN äº†ï¼Œforward è¿‡ç¨‹éœ€è¦å¯¹ RNN å•å…ƒå¾ªç¯ <code>T</code> æ¬¡ï¼ˆ<code>T</code>ä¸ºåºåˆ—é•¿åº¦ï¼‰ï¼Œåœ¨å¾ªç¯å†…éƒ¨æ¯æ¬¡è®°å¾—æ›´æ–° $\boldsymbol{h}_t$ å³å¯ã€‚</p>

<p>backward è¿‡ç¨‹å’Œä»¥å‰çš„ç¥ç»ç½‘ç»œä¸å¤ªä¸€æ ·ï¼ŒRNN ä»ä¸Šæ¸¸ä¼ è¿‡æ¥çš„æ¢¯åº¦ä¸åªä¸€ä¸ªï¼Œé™¤äº†ä»å³è¾¹ä¼ è¿‡æ¥çš„æ¢¯åº¦å¤–ï¼Œ
è¿˜æœ‰æ¯ä¸ªæ—¶é—´ç‚¹ï¼ˆä¸Šé¢ï¼‰ä¼ è¿‡æ¥çš„æ¢¯åº¦ã€‚é¦–å…ˆéœ€è¦é€†åºå¾ªç¯ï¼Œç„¶åæ¯ä¸ªå¾ªç¯å†…æ›´æ–° RNN å•å…ƒéœ€è¦çš„æ¢¯åº¦å€¼ã€‚
æ­¤å¤–ï¼Œåœ¨ RNN ä¸­ï¼ŒWx, Wh, b è¿™ä¸‰ä¸ªå‚æ•°æ˜¯å…±äº«çš„ï¼Œå¯¹æ¯ä¸ªæ—¶é—´æ­¥éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤å®ƒä»¬çš„æ¢¯åº¦æ˜¯ä¸€ä¸ªç´¯åŠ çš„å€¼ã€‚</p>

<pre><code class="language-python">dprev_ht = np.zeros((N, H))
for t in reversed(range(T)):
    dx[:, t, :], dprev_ht, dWxt, dWht, dbt = rnn_step_backward(
        dh[:, t, :] + dprev_ht, cache[t])
    dWx += dWxt
    dWh += dWht
    db += dbt
dh0 = dprev_ht
</code></pre>

<p>åœ¨ç”¨ RNN å¯¹å›¾åƒè¿›è¡Œæ ‡æ³¨å‰ï¼Œè¿˜éœ€è¦è¿›è¡Œè¯åµŒå…¥(word embeding)æ“ä½œã€‚
ç¥ç»ç½‘ç»œä¸èƒ½å°†å•è¯ä½œä¸ºè¾“å…¥ï¼Œæ‰€ä»¥éœ€è¦å°†å•è¯æ˜ å°„ä¸ºå•è¯ç´¢å¼•çš„å½¢å¼ã€‚</p>

<p>ç°åœ¨å°±å¯ä»¥æ¥æ­å»º RNN çš„æ¶æ„äº†ã€‚é¦–å…ˆéœ€è¦æŠŠå›¾åƒç» CNN æå–çš„ç‰¹å¾ï¼ˆä½œä¸šä¸­é‡‡ç”¨çš„æ˜¯åœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ VGG16 æ¨¡å‹çš„ fc7 å±‚æå–å¾—åˆ°çš„ç‰¹å¾ï¼‰é€šè¿‡å…¨è¿æ¥å±‚è½¬æ¢ä¸ºåˆå§‹çš„éšè—çŠ¶æ€ï¼ˆ$\boldsymbol{h}_0$ï¼‰ï¼Œæ¥ç€å°† captions åšè¯åµŒå…¥è¾“å…¥ RNN å•å…ƒä¸­ï¼Œå†åˆ©ç”¨ä¸€ä¸ªä»¿å°„å˜æ¢å°† RNN å•å…ƒçš„è¾“å‡ºè½¬æ¢ä¸ºå•è¯å­—å…¸ç´¢å¼•ï¼Œæ¥ç€é‡‡ç”¨ softmax æŸå¤±è®¡ç®— lossã€‚</p>

<pre><code class="language-python">h0, h0cache = affine_forward(features, W_proj, b_proj)
weout, wecache = word_embedding_forward(captions_in, W_embed)

if self.cell_type == 'rnn':
    rnnout, rnncache = rnn_forward(weout, h0, Wx, Wh, b)

x, xcache = temporal_affine_forward(rnnout, W_vocab, b_vocab)
loss, dx = temporal_softmax_loss(x, captions_out, mask)
</code></pre>

<p>ä¸Šé¢æè¿°çš„æ˜¯ RNN è®­ç»ƒè¿‡ç¨‹ï¼Œæµ‹è¯•æ—¶æ²¡æœ‰çœŸå€¼æ ‡æ³¨ä½œä¸ºè¾“å…¥ï¼Œéœ€è¦ä¸€ä¸ªèµ·å§‹å•è¯ï¼ˆ<code>&lt;START&gt;</code>ï¼‰ä½œä¸ºå¼€å§‹ï¼Œç„¶åæŒ‰åºåˆ—ä¾æ¬¡æ›´æ–°éšè—çŠ¶æ€ï¼Œå¹¶é¢„æµ‹è¾“å‡ºä¸‹ä¸€ä¸ªæ ‡æ³¨å•è¯ã€‚</p>

<pre><code class="language-python">prev_h, _ = affine_forward(features, W_proj, b_proj)
captions[:, 0] = self._start
x = self._start * np.ones((N, ), dtype=np.int32)
for t in range(1, max_length):
    embed, _ = word_embedding_forward(x, W_embed)

    if self.cell_type == 'rnn':
        next_h, _ = rnn_step_forward(embed, prev_h, Wx, Wh, b)

    prev_h = next_h
    out, _ = affine_forward(next_h, W_vocab, b_vocab)
    idx = np.argmax(out, axis=1)
    captions[:, t] = idx
</code></pre>

<h2 id="lstm-captioning">LSTM captioning</h2>

<p>RNN åº”è¯¥èƒ½å¤Ÿè®°ä½è®¸å¤šæ—¶é—´æ­¥ä¹‹å‰è§è¿‡çš„ä¿¡æ¯ï¼Œä½†å®é™…ä¸­ç”±äºæ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing gradient problemï¼‰é—®é¢˜ï¼Œ
éšç€å±‚æ•°çš„å¢åŠ ï¼Œç½‘ç»œå°†å˜å¾—æ— æ³•è®­ç»ƒã€‚LSTM(Long Short Term Memory)å’Œ GRU éƒ½æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜è€Œæå‡ºçš„ã€‚</p>

<p>LSTM å•å…ƒç»“æ„å¦‚ä¸‹ï¼š</p>

<p><figure><img src="./images/lstm.png" alt=""></figure></p>

<p>forward è¿‡ç¨‹è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p>

<p><span  class="math">\[
\begin{align}
\begin{pmatrix}
i \\
f \\
o \\
g
\end{pmatrix} & =
\begin{pmatrix}
\sigma \\
\sigma \\
\sigma \\
\tanh
\end{pmatrix} \,
\mathbf{W}
\begin{pmatrix}
h*{t-1} \\
x_t
\end{pmatrix} \\
\\
c_t & = f \odot c*{t-1} + i \odot g \\
h_t & = o \odot \tanh(c_t)
\end{align}
\]</span></p>

<p>æ³¨æ„åˆ°æ¯ä¸ª LSTM å•å…ƒæœ‰ 3 ä¸ªè¾“å…¥ï¼š$c, h, x$ã€‚å®é™…è®¡ç®—æ—¶ 4 ä¸ª gate çš„çº¿æ€§éƒ¨åˆ†å¯ä»¥é€šè¿‡ä¸€æ¬¡è®¡ç®—å®Œæˆï¼Œç„¶åå°†ä¸åŒ gate å¯¹åº”çš„å€¼åˆ†å¼€å³å¯ã€‚</p>

<pre><code class="language-python">H = prev_h.shape[1]
z = x @ Wx + prev_h @ Wh + b
igate = sigmoid(z[:, :H])
fgate = sigmoid(z[:, H:2 * H])
ogate = sigmoid(z[:, 2 * H:3 * H])
ggate = np.tanh(z[:, 3 * H:])

next_c = fgate * prev_c + igate * ggate
next_h = ogate * np.tanh(next_c)
</code></pre>

<p>backward æ—¶ï¼Œç›¸æ¯” RNNï¼Œåä¼ è¿‡æ¥çš„å€¼æœ‰ä¸¤ä¸ª <strong><code>dnext_h</code>, <code>dnext_c</code></strong>ã€‚æ±‚ï¼š
<code>dx</code>, <code>dWx</code>, <code>dWh</code>, <code>db</code>, <code>dprev_h</code> å’Œ <code>dprev_c</code> çš„æ¢¯åº¦ã€‚å¼„æ¸…æ¥šå“ªäº›å˜é‡ä¹‹é—´æœ‰å…³è”ï¼Œç„¶ååˆ©ç”¨é“¾å¼æ³•åˆ™å³å¯ï¼š</p>

<pre><code class="language-python">dogate = dnext_h * np.tanh(next_c)
dnext_c += dnext_h * ogate * (1.0 - np.tanh(next_c)**2)
dfgate = dnext_c * prev_c
dprev_c = dnext_c * fgate
digate = dnext_c * ggate
dggate = dnext_c * igate

dz = np.zeros((N, 4 * H))
dz[:, :H] = digate * igate * (1.0 - igate)
dz[:, H:2 * H] = dfgate * fgate * (1. - fgate)
dz[:, 2 * H:3 * H] = dogate * ogate * (1.0 - ogate)
dz[:, 3 * H:4 * H] = dggate * (1.0 - ggate**2)

dx = dz @ Wx.T
dWx = x.T @ dz
dprev_h = dz @ Wh.T
dWh = prev_h.T @ dz
db = np.sum(dz, axis=0)
</code></pre>

<p>å®Œæ•´çš„ LSTM å¤§ä½“å’Œ RNN ç›¸åŒï¼Œæ³¨æ„å¤šäº†ä¸€ä¸ªå˜é‡ <code>c</code>ï¼Œä¸è®ºæ˜¯ forward å’Œ backward éƒ½è®°å¾—åœ¨å¾ªç¯é‡Œæ›´æ–°å³å¯ã€‚</p>

<h2 id="network-visualization">Network Visualization</h2>

<p>ä¹‹å‰è®­ç»ƒæ¨¡å‹éƒ½æ˜¯åˆ©ç”¨ SGD æ¥æ›´æ–°æ¨¡å‹å‚æ•°ä½¿å…¶è¾¾åˆ°æŸå¤±å‡½æ•°å®šä¹‰ä¸‹çš„è¦æ±‚ã€‚è€Œåœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„é¢„è®­ç»ƒæ¨¡å‹æ¥å®šä¹‰ç›¸å¯¹äºå›¾åƒçš„æŸå¤±å‡½æ•°ï¼Œåˆ©ç”¨åå‘ä¼ æ’­è®¡ç®—å›¾åƒåƒç´ çš„æ¢¯åº¦ï¼Œä¿æŒæ¨¡å‹ä¸å˜ï¼Œé€šè¿‡æ›´æ–°å›¾åƒæ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚</p>

<p>ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ–¹é¢çš„å†…å®¹ï¼š</p>

<ul>
<li>æ˜¾è‘—æ€§å›¾ï¼ˆSaliency Mapsï¼‰</li>
</ul>

<p>æ˜¾è‘—æ€§å›¾å‘Šè¯‰æˆ‘ä»¬å›¾åƒä¸­æ¯ä¸ªåƒç´ å½±å“å›¾åƒç±»åˆ«åˆ†æ•°çš„ç¨‹åº¦ã€‚é€šè¿‡è®¡ç®—æ­£ç¡®ç±»æœªè§„èŒƒåŒ–çš„åˆ†æ•°ç›¸å¯¹äºæ¯ä¸ªåƒç´ çš„æ¢¯åº¦æ¥å¾—åˆ°ã€‚</p>

<pre><code class="language-python">scores = model(X) # correct class scores
scores = scores.gather(1, y.view(-1, 1)).squeeze() # backward
scores.backward(torch.ones(X.size(0)))

 # image gradient
saliency = X.grad

 # absolute the value and take the maximum value over the 3 channels
saliency = torch.abs(saliency)
saliency, _ = torch.max(saliency, dim=1)
</code></pre>

<ul>
<li>Fooling images</li>
</ul>

<p>Fooling images åˆ™æ˜¯åœ¨ç»™å®šå›¾åƒå’Œç±»åˆ«æ—¶ï¼Œé€šè¿‡æ¢¯åº¦ä¸Šå‡æ³•ä¸æ–­åœ°æ›´æ–°å›¾åƒï¼Œæœ€åä½¿å¾—æ¨¡å‹è®¤ä¸ºè¯¥å›¾åƒå°±æ˜¯è¿™ä¸ªç±»åˆ«çš„å›¾åƒä¸ºæ­¢ã€‚</p>

<pre><code class="language-python">while (True):
    scores = model(X*fooling)
    idx = torch.argmax(scores)

    if idx.item() == target_y:
        break

    scores[0, target_y].backward()

    dX = X_fooling.grad.data

    # update image using gradient ascent
    X_fooling.data += learning_rate * (dX / dX.norm())

    X_fooling.grad.zero_()
</code></pre>

<ul>
<li>ç±»åˆ«å¯è§†åŒ–ï¼ˆClass Visualizationï¼‰</li>
</ul>

<p>è¿™é‡Œå’Œ fooling images å·®ä¸å¤šï¼Œéƒ½æ˜¯é¢„è®­ç»ƒçš„æ¨¡å‹é€šè¿‡æ¢¯åº¦ä¸Šå‡å°†è¾“å…¥çš„éšæœºå™ªéŸ³å›¾åƒå˜ä¸ºæŒ‡å®šç±»åˆ«çš„å›¾åƒã€‚</p>

<pre><code class="language-python">scores = model(img)
loss = scores[0, target_y] - l2_reg * img.norm()
loss.backward()
grad = img.grad.data
img.data += learning_rate * grad
img.grad.zero_()
</code></pre>

<h2 id="style-transfer">Style Transfer</h2>

<p>é£æ ¼è¿ç§»çš„ç›®çš„æ˜¯å°†å‚è€ƒå›¾åƒçš„é£æ ¼åº”ç”¨äºç›®æ ‡å›¾åƒï¼ŒåŒæ—¶ä¿ç•™ç›®æ ‡å›¾åƒçš„å†…å®¹ï¼Œä»è€Œç”Ÿæˆä¸€å‰¯æ–°çš„å›¾åƒã€‚</p>

<p><figure><img src="./images/20190329.jpg" alt=""></figure></p>

<p>é£æ ¼è¿ç§»çš„æ€æƒ³ä¸çº¹ç†ç”Ÿæˆçš„æƒ³æ³•å¯†åˆ‡ç›¸å…³ã€‚å®ç°é£æ ¼è¿ç§»èƒŒåçš„å…³é”®æ€æƒ³ä¸æ‰€æœ‰æ·±åº¦å­¦ä¹ ç®—æ³•çš„æ€æƒ³ä¸€æ ·ï¼š
éœ€è¦å…ˆå®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°å®šä¹‰è¦å®ç°çš„ç›®æ ‡ï¼Œç„¶åé‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ã€‚
ç›®æ ‡å°±æ˜¯ä¿å­˜åŸå§‹å›¾åƒå†…å®¹çš„åŒæ—¶å®ç°é£æ ¼åŒ–ï¼Œè‹¥èƒ½åœ¨æ•°å­¦ä¸Šç»™å‡º content å’Œ style çš„å®šä¹‰ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°
å¯ä»¥å®šä¹‰å¦‚ä¸‹ï¼š</p>

<pre><code>loss = distance(style(reference_image) - style(generated_image)) +
       distance(content(original_image) - content(generated_image))
</code></pre>

<p>è¿™é‡Œçš„ <code>distance</code> æ˜¯ä¸€ä¸ªèŒƒæ•°ï¼Œå¦‚ L2 èŒƒæ•°ã€‚<code>content</code> å’Œ <code>style</code> åˆ†åˆ«æ˜¯è®¡ç®—è¾“å…¥å›¾åƒå†…å®¹å’Œé£æ ¼
çš„å‡½æ•°ã€‚</p>

<h3 id="content-loss">content loss</h3>

<p>å†…å®¹æŸå¤±æè¿°çš„æ˜¯ç½‘ç»œä»ç›®æ ‡å›¾åƒæå–å‡ºçš„ç‰¹å¾å›¾ä¸ä»ç”Ÿæˆå›¾åƒæå–çš„ç‰¹å¾å›¾ä¹‹é—´çš„å·®åˆ«ã€‚é€šå¸¸é€‰æ‹©çš„æ˜¯é è¿‘
é¡¶éƒ¨çš„æŸä¸€ç‰¹å¾å›¾æ¥è¿›è¡Œé€å…ƒç´ æ¯”è¾ƒã€‚ä»£ç å¦‚ä¸‹ï¼š</p>

<pre><code class="language-python">def content_loss(content_weight, content_current, content_original):
    &quot;&quot;&quot;
    Compute the content loss for style transfer.
    
    Inputs:
    - content_weight: Scalar giving the weighting for the content loss.
    - content_current: features of the current image; this is a PyTorch Tensor of shape
      (1, C_l, H_l, W_l).
    - content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l).
    
    Returns:
    - scalar content loss
    &quot;&quot;&quot;
    loss = content_weight * torch.sum((content_current - content_original)**2)
    return loss
</code></pre>

<h3 id="style-loss">style loss</h3>

<p>ä¸åŒäºå†…å®¹æŸå¤±ï¼Œé£æ ¼æŸå¤±ä½¿ç”¨å·ç§¯ç½‘ç»œçš„å¤šä¸ªå±‚æ¥å®šä¹‰ï¼Œä»¥æ­¤æ¥æ•æ‰å‚è€ƒå›¾åƒå’Œç”Ÿæˆå›¾åƒä¸Šä¸åŒç©ºé—´å°ºåº¦ä¸Š
çš„ä¿¡æ¯ã€‚ä½¿ç”¨ Gram Matrix æ¥è¡¨ç¤ºä¸åŒæ¿€æ´»å±‚ä¹‹é—´çš„ç›¸å…³æ€§ï¼šæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆå›¾åƒçš„æ¿€æ´»ç»Ÿè®¡é‡ä¸é£æ ¼å›¾åƒçš„
æ¿€æ´»ç»Ÿè®¡é‡ç›¸åŒ¹é…ã€‚æœ‰å¾ˆå¤šç§æ–¹æ³•å¯ä»¥æ¥è¡¨ç¤ºè¿™ç§ç›¸å…³ï¼Œä½† Gram Matrix æ˜“äºè®¡ç®—ä¸”æ•ˆæœå¾ˆå¥½ã€‚</p>

<p>å¯¹äº shape ä¸º $(C_l, M_l)$ çš„ç‰¹å¾å›¾ $F^l$ ï¼Œå…¶ Gram çŸ©é˜µ shape ä¸º $(C_l, C_l)$:</p>

<p><span  class="math">\[
G_{ij}^l = \sum_k {F_{ik}^l F_{jk}^l}
\]</span></p>

<p>å‡å®š $G^l$ ä¸ºå½“å‰å›¾åƒçš„ Gram çŸ©é˜µï¼Œ$A^l$ ä¸ºå‚è€ƒé£æ ¼å›¾åƒçš„ç‰¹å¾å›¾ Gram çŸ©é˜µï¼Œ$w_l$ ä¸ºæƒé‡ï¼Œ
é‚£ä¹ˆ $l$ å±‚çš„é£æ ¼æŸå¤±å¯ä»¥ç®€å•çš„å®šä¹‰ä¸ºä¸¤ä¸ª Gram çŸ©é˜µä¹‹é—´çš„æ¬§æ°è·ç¦»ï¼š</p>

<p><span  class="math">\[
L_s^l = w_l \sum_{i,j} {(G_{ij}^l - A_{ij}^l)^2}
\]</span></p>

<p>è€Œé£æ ¼æŸå¤±æ˜¯å¤šä¸ªå±‚çš„æŸå¤±å’Œï¼š</p>

<p><span  class="math">\[
L_s = \sum_{l \in \mathcal{L}} {L_s^l}
\]</span></p>

<p>é¦–å…ˆå®ç° Gram çŸ©é˜µçš„è®¡ç®—ï¼š</p>

<pre><code class="language-python">def gram_matrix(features, normalize=True):
    &quot;&quot;&quot;
    Compute the Gram matrix from features.
    
    Inputs:
    - features: PyTorch Tensor of shape (N, C, H, W) giving features for
      a batch of N images.
    - normalize: optional, whether to normalize the Gram matrix
        If True, divide the Gram matrix by the number of neurons (H * W * C)
    
    Returns:
    - gram: PyTorch Tensor of shape (N, C, C) giving the
      (optionally normalized) Gram matrices for the N input images.
    &quot;&quot;&quot;
    N, C, H, W = features.size()
    features_reshaped = features.reshape(N, C, H * W)
    gram = torch.bmm(features_reshaped, features_reshaped.transpose(1, 2))
    if normalize:
        gram /= H * W * C
    return gram
</code></pre>

<p>æ¥ç€ï¼Œæˆ‘ä»¬å®ç°é£æ ¼æŸå¤±å‡½æ•°ï¼š</p>

<pre><code class="language-python">def style_loss(feats, style_layers, style_targets, style_weights):
    &quot;&quot;&quot;
    Computes the style loss at a set of layers.
    
    Inputs:
    - feats: list of the features at every layer of the current image, as produced by
      the extract_features function.
    - style_layers: List of layer indices into feats giving the layers to include in the
      style loss.
    - style_targets: List of the same length as style_layers, where style_targets[i] is
      a PyTorch Tensor giving the Gram matrix of the source style image computed at
      layer style_layers[i].
    - style_weights: List of the same length as style_layers, where style_weights[i]
      is a scalar giving the weight for the style loss at layer style_layers[i].
      
    Returns:
    - style_loss: A PyTorch Tensor holding a scalar giving the style loss.
    &quot;&quot;&quot;
    # Hint: you can do this with one for loop over the style layers, and should
    # not be very much code (~5 lines). You will need to use your gram_matrix function.
    loss = torch.FloatTensor([0]).type(dtype)
    for i, idx in enumerate(style_layers):
        gram = gram_matrix(feats[idx])
        loss += torch.sum(style_weights[i] * (gram - style_targets[i])**2)       
    return loss
</code></pre>

<h3 id="totalvariation-regularization">Total-variation regularization</h3>

<p>é™¤äº†å†…å®¹æŸå¤±å’Œé£æ ¼æŸå¤±ä¹‹å¤–ï¼Œè¿˜éœ€è¦æ·»åŠ ä¸€ä¸ªå…¨å˜åˆ†æ­£åˆ™åŒ–æŸå¤±ï¼Œä½¿ç”Ÿæˆå›¾åƒ
çš„åƒç´ å…·æœ‰ç©ºé—´è¿ç»­æ€§å’Œå¹³æ»‘ï¼Œé¿å…å›¾åƒè¿‡åº¦åƒç´ åŒ–ã€‚</p>

<p>å…¨å˜åˆ†æŸå¤±å®šä¹‰ä¸ºæ°´å¹³å’Œå‚ç›´æ–¹å‘ç›¸é‚»åƒç´ å·®çš„å¹³æ–¹å’Œï¼Œå¯¹äºä¸åŒçš„é€šé“ä¹‹é—´ä¹Ÿæ˜¯ç›¸åŠ ã€‚</p>

<pre><code class="language-python">def tv_loss(img, tv_weight):
    &quot;&quot;&quot;
    Compute total variation loss.
    
    Inputs:
    - img: PyTorch Variable of shape (1, 3, H, W) holding an input image.
    - tv_weight: Scalar giving the weight w_t to use for the TV loss.
    
    Returns:
    - loss: PyTorch Variable holding a scalar giving the total variation loss
      for img weighted by tv_weight.
    &quot;&quot;&quot;
    # Your implementation should be vectorized and not require any loops!
    hsum = torch.sum((img[:,:,:-1,:] - img[:,:,1:,:])**2)
    wsum = torch.sum((img[:,:,:,:-1] - img[:,:,:,1:])**2)
    return tv_weight * (hsum + wsum)
</code></pre>

<p>åœ¨é£æ ¼è¿ç§»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æœ€å°åŒ–çš„æŸå¤±ä¸ºå†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œå…¨å˜å·®æŸå¤±è¿™ä¸‰éƒ¨åˆ†ä¹‹å’Œã€‚
æ¥ä¸‹æ¥ï¼Œåªéœ€è¦å°†è¿™ä¸‰éƒ¨åˆ†ç»„åˆèµ·æ¥ï¼Œåˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥å¾—åˆ°æœ€åçš„å›¾åƒå³å¯ã€‚å…·ä½“å¯ä»¥å‚è€ƒ
<a href="https://github.com/whu-pzhang/cs231n/blob/master/assignment3/StyleTransfer-PyTorch.ipynb">StyleTransfer-Pytorch.ipynb</a></p>

<h2 id="gan">GAN</h2>

<p>åœ¨æ­¤ä¹‹å‰ï¼Œcs231nä¸­æ‰€æœ‰çš„ç¥ç»ç½‘ç»œéƒ½æ˜¯åˆ¤åˆ«å¼æ¨¡å‹ï¼Œä»ç»™å®šçš„è¾“å…¥å¾—åˆ°ä¸€ä¸ªç±»åˆ«æ ‡è®°è¾“å‡ºã€‚å…¶åº”ç”¨èŒƒå›´ä»å›¾åƒåˆ†ç±»
åˆ°ç”Ÿæˆå›¾åƒæè¿°ã€‚åœ¨è¿™ä¸€å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¥ç»ç½‘ç»œæ¥æ„å»ºç”Ÿæˆæ¨¡å‹ã€‚</p>

<p>2014å¹´ï¼Œ<a href="https://arxiv.org/abs/1406.2661">Goodfellow et al.</a>æå‡ºäº†è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
ï¼ˆGenerative Adversarial Networksï¼ŒGANï¼‰ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œéœ€è¦æ„å»ºä¸¤ä¸ªä¸åŒçš„ç½‘ç»œï¼š
ç¬¬ä¸€ä¸ªç½‘ç»œæ˜¯ä¼ ç»Ÿçš„åˆ†ç±»ç½‘ç»œï¼Œç§°ä¸ºåˆ¤åˆ«å™¨ï¼ˆdiscriminatorï¼‰ï¼Œå…¶åŠŸèƒ½æ˜¯åˆ¤æ–­è¾“å…¥å›¾åƒæ˜¯çœŸå®çš„ï¼ˆè¾“å…¥è®­ç»ƒé›†ï¼‰
è¿˜æ˜¯å‡çš„ï¼ˆä¸å±äºè®­ç»ƒé›†ï¼‰ã€‚ç¬¬äºŒä¸ªç½‘ç»œç§°ä¸ºç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ï¼Œå°†éšæœºå™ªå£°ä½œä¸ºè¾“å…¥å¹¶äº§ç”Ÿä¸€å¼ å›¾åƒã€‚
ç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯éª—è¿‡åˆ¤åˆ«å™¨ï¼Œä½¿å…¶è®¤ä¸ºå…¶ç”Ÿæˆçš„å›¾åƒæ˜¯çœŸå®çš„ã€‚</p>

<p>å¯ä»¥æŠŠåˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨çš„åšå¼ˆçœ‹ä½œæ˜¯ä¸€ä¸ªæœ€å°æœ€å¤§çš„è¿‡ç¨‹ï¼š</p>

<p><span  class="math">\[
\min_{G} \max_{D} \mathbb{E}_{x~p_{data}} \left[ \log D(x) \right] + \mathbb{E}_{z~p(z)} \left[ \log (1-D(G(z))) \right]
\]</span></p>

<p>å…¶ä¸­ï¼Œ$z~p(z)$ ä¸ºéšæœºå™ªå£°æ ·æœ¬ï¼Œ$G(z)$ ä¸ºç”Ÿæˆå™¨ $G$ äº§ç”Ÿçš„å›¾åƒï¼Œ$D$ ä¸ºåˆ¤åˆ«å™¨çš„è¾“å‡ºï¼Œè¡¨ç¤ºè¾“å…¥ä¸º
çœŸå®å›¾åƒçš„æ¦‚ç‡ã€‚åœ¨<a href="https://arxiv.org/abs/1406.2661">Goodfellow et al.</a>ä¸­ï¼Œä½œè€…åˆ†æäº†è¿™ä¸ª
æœ€å°æœ€å¤§è¿‡ç¨‹å’Œæœ€å°åŒ–è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´Jensen-Shannonæ•£åº¦çš„å…³è”ã€‚</p>

<p>ä¸ºäº†ä¼˜åŒ–è¿™ä¸ªæœ€å°æœ€å¤§è¿‡ç¨‹ï¼Œå¯ä»¥é€‰æ‹©å¯¹ $G$ è¿›è¡Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼Œå¯¹ $D$ è¿›è¡Œæ¢¯åº¦ä¸Šå‡ä¼˜åŒ–ï¼š</p>

<ol>
<li>æ›´æ–°ç”Ÿæˆå™¨ $G$ ä½¿å¾—åˆ¤åˆ«å™¨ä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æœ€å°</li>
<li>æ›´æ–°åˆ¤åˆ«å™¨ $D$ ä½¿å¾—åˆ¤åˆ«å™¨ä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æœ€å¤§</li>
</ol>

<p>ä½†æ˜¯ä¸Šè¿°ä¸¤ä¸ªè¿‡ç¨‹å®é™…ä¸­éš¾ä»¥workã€‚å› æ­¤ï¼Œå®é™…ä¸­<strong>æ›´æ–°ç”Ÿæˆå™¨çš„å‡†åˆ™æ˜¯æœ€å¤§åŒ–åˆ¤åˆ«å™¨ä½œå‡ºé”™è¯¯åˆ¤æ–­çš„æ¦‚ç‡</strong>ã€‚</p>

<p>è¯¥å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº¤æ›¿æ‰§è¡Œå¦‚ä¸‹æ›´æ–°ï¼š</p>

<ol>
<li>æœ€å¤§åŒ–åˆ¤åˆ«å™¨ä½œå‡ºé”™è¯¯åˆ¤æ–­çš„æ¦‚ç‡æ¥æ›´æ–°ç”Ÿæˆå™¨ $G$:</li>
</ol>

<p><span  class="math">\[
\max_{G} \mathbb{E}_{z~p(z)} \left[ \log D(G(z)) \right]
\]</span></p>

<ol start="2">
<li>æœ€å¤§åŒ–åˆ¤åˆ«å™¨åœ¨çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®ä¸Šä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æ¥æ›´æ–°åˆ¤åˆ«å™¨ $D$</li>
</ol>

<p><span  class="math">\[
\max_{D} \mathbb{E}_{x~p_{data}} \left[ \log D(x) \right] + \mathbb{E}_{z~p_{z}} \left[ \log (1-D(G(z))) \right]
\]</span></p>

<p>å®é™…ä¸Šï¼Œè‡ª2014å¹´GANæå‡ºä»¥æ¥ï¼Œæœ‰å…³GANçš„è®ºæ–‡å±‚å‡ºä¸ç©·ï¼Œç›¸è¾ƒäºå…¶ä»–çš„ç”Ÿæˆæ¨¡å‹ï¼ŒGANèƒ½ç”Ÿæˆè´¨é‡æœ€é«˜å›¾åƒçš„åŒæ—¶ï¼Œ
ä¹Ÿéœ€è¦é«˜è¶…çš„è®­ç»ƒæŠ€å·§ã€‚è¿™ä¸ª<a href="https://github.com/soumith/ganhacks">repo</a>é‡ŒåŒ…å«äº†è®­ç»ƒGANçš„17ä¸ªtrickã€‚
æå‡GANè®­ç»ƒçš„ç¨³å®šæ€§å’Œé²æ£’æ€§æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ç ”ç©¶é¢†åŸŸï¼Œæ¯å¤©éƒ½ä¼šç”¨å°çš„paperå‡ºæ¥ã€‚æœ€è¿‘çš„GANæ•™ç¨‹ï¼Œå¯ä»¥çœ‹
<a href="https://arxiv.org/abs/1701.00160">è¿™é‡Œ</a>ã€‚
æœ€è¿‘å°†ç›®æ ‡å‡½æ•°å˜ä¸ºWassersteinè·ç¦»çš„GANæ¨¡å‹ï¼ˆ<a href="https://arxiv.org/abs/1701.07875">WGAN</a>ï¼Œ<a href="https://arxiv.org/abs/1704.00028">WGAN-GP</a>ï¼‰è·å¾—äº†æ›´ç¨³å®šçš„ç»“æœã€‚</p>

<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒGANä¸æ˜¯è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„å”¯ä¸€æ–¹æ³•ï¼å¦ä¸€ä¸ªæµè¡Œçš„æ–¹æ³•æ˜¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Autoencodersï¼‰
ï¼ˆç”±<a href="https://arxiv.org/abs/1312.6114">here</a> å’Œ <a href="https://arxiv.org/abs/1401.4082">here</a>å…±åŒå‘ç°ï¼‰ã€‚VAEæ˜“äºè®­ç»ƒï¼Œä½†å…¶ç”Ÿæˆçš„å›¾åƒè´¨é‡è¿œä¸å¦‚GANã€‚</p>

<p>GANçš„æŸå¤±å‡½æ•°æ˜¯ç”¨BCEï¼ˆBinary Cross-Entropyï¼‰å®šä¹‰çš„ï¼Œä¹Ÿå³æ˜¯å¯¹æ•°å›å½’çš„æŸå¤±å‡½æ•°ï¼š</p>

<p><span  class="math">\[
bce(s,y) = -y * \log(s) - (1-y) * \log(1-s)
\]</span></p>

<p>è¿™é‡Œçš„$s$ä¸ºç»sigmoidå‡½æ•°ä½œç”¨åå„ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œå³ $s = \sigma(x)$ï¼Œå…¶å€¼åœ¨0ï½1ä¹‹é—´ã€‚é‚£ä¹ˆç›´æ¥
è®¡ç®—bce loss çš„æ—¶å€™å°±ä¼šæœ‰æ•°å€¼ä¸ç¨³å®šçš„é—®é¢˜ï¼šè‹¥sçš„å€¼å¾ˆå°ï¼Œé‚£ä¹ˆ $\log(s)$ ä¾¿ä¼šæ¥è¿‘ $-\infty$ã€‚
å› æ­¤ï¼Œéœ€åšå¦‚ä¸‹ä¼˜åŒ–ï¼š</p>

<p><span  class="math">\[
\begin{align}
& -y \log(\sigma(x)) - (1-y) \log(1 - \sigma(x)) \\
&= -y \log(\frac{1}{1+e^{-x}}) - (1-y) \log(e^{-x} - \frac{1}{1+e^{-x}}) \\
&= y \log(1 + e^{-x}) + (1 - y) (x + \log(1 + e^{-x})) \\
&= (1 - y) x + \log(1 + e^{-x}) \\
&= x - xy + \log(1 + e^{-x})  % é¿å… x < 0æ—¶ï¼Œ exp(-x) æº¢å‡º \\
&= -xy + \log(1 + e^x)
\end{align}
\]</span></p>

<p>ä¸ºäº†ç¡®ä¿ç¨³å®šæ€§ï¼Œå®ç°å¦‚ä¸‹ï¼š</p>

<pre><code class="language-python">def bce_loss(input, target):
    &quot;&quot;&quot;
    Numerically stable version of the binary cross-entropy loss function.

    As per https://github.com/pytorch/pytorch/issues/751
    See the TensorFlow docs for a derivation of this formula:
    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits

    Inputs:
    - input: PyTorch Tensor of shape (N, ) giving scores.
    - target: PyTorch Tensor of shape (N,) containing 0 and 1 giving targets.

    Returns:
    - A PyTorch Tensor containing the mean BCE loss over the minibatch of input data.
    &quot;&quot;&quot;
    neg_abs = - input.abs()
    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()
    return loss.mean()
</code></pre>

<p>åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä¾¿å¯ä»¥åˆ†åˆ«å®ç°åˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°äº†ã€‚è¿™é‡Œå°±ä¸è´´ä»£ç äº†ã€‚
åé¢çš„éƒ¨åˆ†æ˜¯ä»‹ç»ä¸åŒçš„GANä»¥åŠå®ç°äº†ã€‚ä½œä¸šå¯ä»¥å‚è€ƒæˆ‘çš„repoï¼š<a href="https://github.com/whu-pzhang/cs231n/blob/master/assignment3/GANs-PyTorch.ipynb">GANs-Pytorch.ipynb</a></p>

<h2 id="æ€»ç»“">æ€»ç»“</h2>

<p>ä½œä¸š3çš„å†…å®¹æ›´å¤šçš„æ˜¯å°†æ·±åº¦å­¦ä¹ çš„å¤šä¸ªåº”ç”¨å±•ç¤ºä¸€ä¸‹ï¼Œç„¶åé€šè¿‡ä½œä¸šçš„å½¢å¼æ¥ç†Ÿæ‚‰æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚
æ¶‰åŠåˆ°çš„å†…å®¹å¾ˆä¸°å¯Œï¼Œæƒ³è¦æ·±å…¥ç†è§£çš„è¯ï¼Œéœ€è¦è‡ªå·±å»æŸ¥çœ‹ç›¸å…³æ–‡çŒ®æ‰è¡Œã€‚</p>

<p>è‡³æ­¤ï¼Œcs231nçš„ä½œä¸šç¬”è®°å…¨éƒ¨å®Œæˆï¼ğŸ‰</p>
    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">æ–‡ç« ä½œè€…</span>
    <span class="item-content">pzhang</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">ä¸Šæ¬¡æ›´æ–°</span>
    <span class="item-content">2018-12-20</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">è®¸å¯åè®®</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></span>
  </p>
</div>

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/python/">Python</a>
          
          <a href="/tags/numpy/">NumPy</a>
          
          <a href="/tags/pytorch/">PyTorch</a>
          
        </div>

      
      <nav class="post-nav">
        
        
          <a class="next" href="/cs231n-assignment2/">
            <span class="next-text nav-default">cs231nä½œä¸š2ç¬”è®°</span>
            <span class="prev-text nav-mobile">ä¸‹ä¸€ç¯‡</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:pzhang.omega@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/whu-pzhang" class="iconfont icon-github" title="github"></a>
  <a href="https://whu-pzhang.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    ç”± <a class="hexo-link" href="https://gohugo.io">Hugo</a> å¼ºåŠ›é©±åŠ¨
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    ä¸»é¢˜ - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    
      2014 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">whu-pzhang</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
